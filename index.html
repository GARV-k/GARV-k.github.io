<!DOCTYPE html>
<html>
<head>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Nissim Maruani</title>
	<link rel="icon" href="img/favicon.png">

	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com"> 
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@200&display=swap" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@500&display=swap" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@600&family=Space+Mono:ital@1&display=swap" rel="stylesheet">
	<link href="style.css" rel="stylesheet">
</head>
<body>
	<div class="container">
		<img class="profile-img" src="img/profile.jpeg" alt="Profile Picture">
		<div>
			<h1>Nissim Maruani</h1>
			<p class="contact"> <a class="custom-link" href="mailto:nissim.maruani@inria.fr">Contact</a> | <a class="custom-link" href="https://www.github.com/nissmar"> GitHub</a>  | <a class="custom-link" href="https://www.linkedin.com/in/nissim-maruani/"> LinkedIn</a> </p>
            <div class="bio">				
                <p>I am a first year PhD student at INRIA, under the supervision of <a class="custom-link" href="https://team.inria.fr/titane/pierre-alliez/">Pierre Alliez</a> (<a class="custom-link" href="https://www.inria.fr/fr/titane">Titane team</a>) and <a class="custom-link"  href="https://pages.saclay.inria.fr/mathieu.desbrun/">Mathieu Desbrun</a> (<a class="custom-link"  href="https://www.inria.fr/fr/geomerix">Geomerix team</a>). My research topic combines geometry processing with deep learning. Our goal is to enable neural networks to generate efficient 3D shapes in a differentiable pipeline.  </p>
            </div>
		</div>
	</div>


	<h2>Publications</h2>

	<!-- <ul class="pub-line"></ul> -->
	<!-- <ul class="pub-line"></ul> -->

	<ul class="pub">

        <div class="container">
			<a href="https://nissmar.github.io/voromesh.github.io/">
            <img class="pub-img" src="img/Voromesh.png" alt="Publication 1 Image">
			</a>
			<div>
				<a class="pub-title" href="https://nissmar.github.io/voromesh.github.io/"> VoroMesh: Learning Watertight Surface Meshes with Voronoi Diagrams</a>
				<div class="pub-authors"> Nissim Maruani, Roman Klokov, Maks Ovsjanikov, Pierre Alliez, Mathieu Desbrun </div> 

				<div class="pub-abstract">
					In stark contrast to the case of images, finding a concise, learnable discrete representation of 3D surfaces remains a challenge. In particular, while polygon meshes are arguably the most common surface representation used in geometry processing, their irregular and combinatorial structure often make them unsuitable for learning-based applications. In this work, we present VoroMesh, a novel and differentiable Voronoi-based representation of water- tight 3D shape surfaces. From a set of 3D points (called generators) and their associated occupancy, we define our boundary representation through the Voronoi diagram of the generators as the subset of Voronoi faces whose two associated (equidistant) generators are of opposite occupancy: the resulting polygon mesh forms a watertight approximation of the target shape’s boundary. To learn the position of the generators, we propose a novel loss function, dubbed VoroLoss, that minimizes the distance from groundtruth surface samples to the closest faces of the Voronoi diagram which does not require an explicit construction of the entire Voronoi diagram. A direct optimization of the Voroloss to obtain generators on the Thingi32 dataset demonstrates the geometric efficiency of our representation compared to axiomatic meshing algorithms and recent learning-based mesh representations. We further use VoroMesh in a learning-based mesh prediction task from input SDF grids on the ABC dataset, and show comparable performance to state-of-the-art methods while guaranteeing closed output surfaces free of self-intersections.
				</div>
				<div class="pub-conf"> International Conference on Computer Vision (ICCV), 2023</div>

			</div>
        </div>

	</ul>

	<ul class="pub-line"></ul>

	<ul class="pub">

        <div class="container">
			<a href="https://inria.hal.science/hal-04135266#">
            <img class="pub-img" src="img/offset.jpg" alt="Publication 1 Image">
			</a>
			<div>
				<a class="pub-title" href="https://inria.hal.science/hal-04135266#"> Feature-Preserving Offset Mesh Generation from Topology-Adapted Octrees</a>
				<div class="pub-authors">Daniel Zint, Nissim Maruani, Mael Rouxel-Labbé, Pierre Alliez</div> 

				<div class="pub-abstract">We introduce a reliable method to generate offset meshes from input triangle meshes or triangle soups. Our method proceeds in two steps. The first step performs a Dual Contouring method on the offset surface, operating on an adaptive octree that is refined in areas where the offset topology is complex. Our approach substantially reduces memory consumption and runtime compared to isosurfacing methods operating on uniform grids. The second step improves the output Dual Contouring mesh with an offset-aware remeshing algorithm to reduce the normal deviation between the mesh facets and the exact offset. This remeshing process reconstructs concave sharp features and approximates smooth shapes in convex areas up to a user-defined precision. We show the effectiveness and versatility of our method by applying it to a wide range of input meshes. We also benchmark our method on the entire Thingi10k dataset: watertight, 2-manifold offset meshes are obtained for 100% of the cases.</div>
				<div class="pub-conf">Symposium on geometry processing (SGP), 2023</div>

			</div>
		
        </div>
	</ul>
	<!-- <ul class="pub-line"></ul> -->

	<h2>Teaching</h2>
	<ul>
		<li> ENS-PSL (2022-Today, Paris, France): exploring new ways of teaching maths with <a class="custom-link"  href="https://mathadata.fr/index.html">MathAData</a>  </li>
		<li> 
			<a class="custom-link"  href="https://www.larotonde-sciences.com">La Rotonde</a> (2018-2019, Saint-Étienne, France): Science Mediation at  <a class="custom-link"  href="https://fondation-lamap.org/en">La main à la pâte</a></li>
	</ul>

	<h2>Education</h2>
	<ul>
		<li> ENS Paris-Saclay (2021-2022, Gif-sur-Yvette, France): Master MVA</li>
		<li> École polytechnique (2018-2022, Saclay, France): Engineering Curriculum </li>
		<li> Lycée Louis-le-Grand (2016-2018, Paris, France): "Classe prépa" </li>
	</ul>


	<h2>Coding projects</h2>

	<div class="container project">
		<a href="https://github.com/nissmar/ARDM" class="code-project">
			<img class="code-img" src="img/coding_projects/ardm.jpg">
			<p class="code-title custom-link">Diffusion Models</p>
		</a>
		<a href="https://github.com/nissmar/VSA" class="code-project">
			<img class="code-img" src="img/coding_projects/vsa.gif">
			<p class="code-title custom-link">VSA</p>
		</a>
		<a href="https://github.com/nissmar/Learning-Active-Contour" class="code-project">
			<img class="code-img" src="img/coding_projects/segmentation.gif">
			<p class="code-title custom-link">U-Net</p>
		</a>
		<a href="https://github.com/nissmar/Radiance-Fields" class="code-project">
			<img class="code-img" src="img/coding_projects/plenoxels.gif">
			<p class="code-title custom-link">Plenoxels</p>
		</a>
		<a href="https://github.com/nissmar/FilmNoise/" class="code-project">
			<img class="code-img" src="img/coding_projects/film-noise.jpg">
			<p class="code-title custom-link">Analog Grain Simulation</p>
		</a>
		<a href="https://github.com/nissmar/Paper_Plane_VCL/" class="code-project">
			<img class="code-img" src="img/coding_projects/airplane.png">
			<p class="code-title custom-link">Paper Plane Simulation</p>
		</a>
		<a href="https://github.com/nissmar/Bouncing_Lasers" class="code-project">
			<img class="code-img" src="img/coding_projects/lasers.gif">
			<p class="code-title custom-link">Laser Simulation</p>
		</a>
		<a href="https://github.com/nissmar/ForgeryDetection" class="code-project">
			<img class="code-img" src="img/coding_projects/forgery.gif">
			<p class="code-title custom-link">Forgery Detection</p>
		</a>

		

		
	</div>



</body>
</html>